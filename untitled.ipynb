{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70198547",
   "metadata": {},
   "source": [
    "## Sequence-to-Sequence RNN Models: Translation Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bc2b67",
   "metadata": {},
   "source": [
    "We will be exploring the fundamentals of sequence-to-sequence models and learn how to implement an RNN-based model for a translation task using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3391ca5",
   "metadata": {},
   "source": [
    "- Comprehend recurrent neural networks (RNN) architecture\n",
    "- Create an Encoder-Decoder model for a translation task \n",
    "- Train and evaluate the model \n",
    "- Create a generator for the translation task \n",
    "- Explain concepts related to Perplexity and BLEU score and use them for evaluating translations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4720aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sekai\\.conda\\envs\\myenv\\python.exe: No module named spacy\n",
      "c:\\Users\\sekai\\.conda\\envs\\myenv\\python.exe: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3642ccab",
   "metadata": {},
   "source": [
    "### Step 1: Importing Require Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca9068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torchdata.datapipes.iter import IterableWrapper, Mapper\n",
    "import torchtext\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# We can also use this section to suppress warnings generated by our code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce1f7d0",
   "metadata": {},
   "source": [
    "Sequence-to-sequence (Seq2Seq) models have revolutionized various natural language processing (NLP) tasks, such as machine translation, text summarization, and chatbots. These models employ Recurrent Neural Networks (RNNs) to process variable-length input sequences and generate variable-length output sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405de8e4",
   "metadata": {},
   "source": [
    "#### History of sequence-to-sequence models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00528ff",
   "metadata": {},
   "source": [
    "Sequence-to-sequence models were introduced as an extension of traditional feedforward neural networks.\n",
    "Researchers realized the need for models that could handle variable-length input and output sequences, such as machine translation.\n",
    "The pioneering work of Sutskever et al. (2014) introduced the use of RNNs for seq2seq models.\n",
    "\n",
    "Here are some main objectives of seq2seq models:\n",
    "- Translation: Translating a sequence from one domain to another (e.g., English to French).\n",
    "- Question answering: Generating a natural language response given an input sentence (e.g., chatbots).\n",
    "- Summarization: Summarizing a long document into a shorter sequence of sentences.\n",
    "And many more applications that involve sequence generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a7af0a",
   "metadata": {},
   "source": [
    "#### RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8881f",
   "metadata": {},
   "source": [
    "RNNs are a class of neural networks designed to process sequential data.\n",
    "They maintain an internal memory($h_t$) to capture information from previous steps and use it for current predictions.\n",
    "RNNs have a recurrent connection that allows information to flow from one step to the next.\n",
    "Recurrent Neural Networks (RNNs) operate on sequences and utilize previous states to influence the current state. Here's the general formulation of a simple RNN:\n",
    "\n",
    "\n",
    "Given:\n",
    "\n",
    "-$ \\mathbf{x}_t $: input vector at time step $t$\n",
    "\n",
    "-$ \\mathbf{h}_{t-1} $: hidden state vector from the previous time step\n",
    "\n",
    "-$ \\mathbf{W}_x $ and $ \\mathbf{W}_h $: weight matrices for the input and hidden state, respectively\n",
    "\n",
    "-$ \\mathbf{b} $: bias vector\n",
    "\n",
    "-$\\sigma$: activation function (often a sigmoid or tanh)\n",
    "\n",
    "The update equations for the hidden state $ \\mathbf{h}_t $ and the output $ \\mathbf{y}_t $ are as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{h}_t &= \\sigma(\\mathbf{W}_x \\cdot \\mathbf{x}_t + \\mathbf{W}_h \\cdot \\mathbf{h}_{t-1} + \\mathbf{b})\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "It can be seen that the hidden state function depends on the previous hidden state as well as the input at time t, which is why it has a collective memory of previous time steps.\n",
    "\n",
    "For the output (if we're making a prediction at each time step):\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{y}_t &= \\text{softmax}(\\mathbf{W}_o \\cdot \\mathbf{h}_t + \\mathbf{b}_o)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$ \\mathbf{W}_o $: weight matrix for the output AND $ \\mathbf{b}_o$: bias vector for the output\n",
    "\n",
    "\n",
    "\n",
    "Depending on the specific task, an RNN cell can either produce an output from $h_t$ or solely transfer it to the succeeding cell, serving as internal memory. While the architecture's ability to retain memory might seem elusive at first glance, let's elucidate this by implementing a simple RNN to handle the following data mechanism:\n",
    "\n",
    "![a title](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/Screenshot%202023-10-19%20at%2011.29.23%E2%80%AFAM.png)\n",
    "\n",
    "\n",
    "The diagram showcases a state machine or transition model with three distinct states, depicted by the prominent purple circles. Each state is distinctly labeled with a value for $ h $: $ h = -1 $, $ h = 0 $, and $ h = 1 $.\n",
    "\n",
    "1. **State $ h = -1 $**:\n",
    "   - Maintains itself when $ x = 1 $ (illustrated by the yellow loop).\n",
    "   - Proceeds to the $ h = 0$ state upon receiving $ x = -1$ (highlighted by the red arrow).\n",
    "\n",
    "2. **State $ h = 0 $**:\n",
    "   - Moves to the $h = -1 $ state when $ x = 1$ (illustrated by the red arrow).\n",
    "   - Advances to the $ h = 1 $ state with $ x = -1$ (marked by the red arrow).\n",
    "\n",
    "3. **State $h = 1 $**:\n",
    "   - Sustains its position when $ x = -1 $ (indicated by the yellow loop).\n",
    "   - Transitions to the $ h = 0 $ state upon receiving $ x = 1 $ (signified by the red arrow).\n",
    "\n",
    "To encapsulate, the diagram effectively portrays transitions among three states based on the input $ x $. Contingent on the prevailing state and the input $ x $, the state machine either transitions to a different state or remains stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416864ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73918d87",
   "metadata": {},
   "source": [
    "We can represent the previously mentioned state machine using the layer detailed below. Use $tanh$ as the $h$ value should fall between [-1, 1]. Note that we have excluded the output for simplification:\n",
    "\n",
    "$$\\begin{align*}\n",
    "W_{xh} & = -10.0 \\\\\n",
    "W_{hh} & = 10.0 \\\\\n",
    "b_h & = 0.0 \\\\\n",
    "x_t & = 1 \\\\\n",
    "h_{\\text{prev}} & = 0.0 \\\\\n",
    "h_t & = \\tanh(x_t \\cdot W_{xh} + h_{\\text{prev}} \\cdot W_{hh} + b_h)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cff2eaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_xh = torch.tensor(-10.0)\n",
    "W_hh = torch.tensor(10.0)\n",
    "b_h = torch.tensor(0.0)\n",
    "x_t = 1\n",
    "h_prev = torch.tensor(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c79206",
   "metadata": {},
   "source": [
    "Consider the following sequence $x_t$ for  $t=0,1,..,7$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b15a18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1, 1, -1, -1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f731a909",
   "metadata": {},
   "source": [
    "Assuming that we start from the initial state $h = 0$,  with the above input vector $x$, the state vector $h$ should look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d09a5c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "H=[-1,-1,0,1,0,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26de248f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 1\n",
      "h_t-1 -1\n",
      "x_t 1\n",
      "h_t -1.0\n",
      "\n",
      "\n",
      "t= 2\n",
      "h_t-1 -1.0\n",
      "x_t 1\n",
      "h_t -1.0\n",
      "\n",
      "\n",
      "t= 3\n",
      "h_t-1 -1.0\n",
      "x_t -1\n",
      "h_t 0.0\n",
      "\n",
      "\n",
      "t= 4\n",
      "h_t-1 0.0\n",
      "x_t -1\n",
      "h_t 1.0\n",
      "\n",
      "\n",
      "t= 5\n",
      "h_t-1 1.0\n",
      "x_t 1\n",
      "h_t 0.0\n",
      "\n",
      "\n",
      "t= 6\n",
      "h_t-1 0.0\n",
      "x_t 1\n",
      "h_t -1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the predicted state values \n",
    "H_hat = []\n",
    "\n",
    "# Loop through each data point in the input sequence X\n",
    "t = 1\n",
    "for x in X:\n",
    "    # Assign the current data point to x_t \n",
    "    print(\"t=\", t)\n",
    "    x_t = x\n",
    "    # Print the value of the previous state (h at time t-1)\n",
    "    print(\"h_t-1\", h_prev.item())\n",
    "\n",
    "    # Compute the current state (h at time t) using the RNN formula with tanh activation \n",
    "    h_t = torch.tanh(x_t * W_xh + h_prev * W_hh + b_h)\n",
    "\n",
    "    # Update h_prev to the current state value for the next iteration \n",
    "    h_prev = h_t\n",
    "\n",
    "    # Print the current input values (x at time t)\n",
    "    print(\"x_t\", x_t)\n",
    "\n",
    "    # Print the computed state value (h at time t)\n",
    "    print(\"h_t\", h_t.item())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Append the current state value to the H_har list after converting it to integer\n",
    "    H_hat.append(int(h_t.item()))\n",
    "\n",
    "    # Increment the time step \n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4383d44",
   "metadata": {},
   "source": [
    "We can evaluate the accuracy of predicted state `H_hat` by comparing it to the actual state `H`. In RNNs, the state $ h_t $ is utilized to predict an output sequence $y_t $ based on the given input sequence $ x_t $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ea91d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1, 0, 1, 0, -1]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74e74ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1, 0, 1, 0, -1]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6318bbd8",
   "metadata": {},
   "source": [
    "While we have pre-defined the $W_{xh}$ and $W_{hh}$  and $b_h$, in practice these values need to be identified through training on data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a8cd7",
   "metadata": {},
   "source": [
    "In practice, modifications and enhancements, such as Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU), are often used to address issues like the vanishing gradient problem in basic RNNs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa186651",
   "metadata": {},
   "source": [
    "An LSTM cell has three main components: an input gate, a forget gate, and an output gate.\n",
    "- The **input gate** controls how much new information should be stored in the cell's memory. It looks at the current input and the previous hidden state and decides which parts of the new input to remember.\n",
    "- The **forget gate** determines what information should be discarded or forgotten from the cell's memory. It considers the current input and the previous hidden state and decides which parts of the previous memory are no longer relevant.\n",
    "- The **output gate** determines what information should be outputted from the cell. It looks at the current input and the previous hidden state and decides which parts of the cell's memory to include in the output.\n",
    "\n",
    "The key idea behind LSTM cells is that they have a separate memory state that can selectively retain or forget information over time. This helps them handle long-range dependencies and remember important information from earlier steps in a sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01060f",
   "metadata": {},
   "source": [
    "### Sequence-to-Sequence Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7838766c",
   "metadata": {},
   "source": [
    "Seq2seq models have an Encoder-Decoder structure. The encoder encodes the inputs sequence into a fixed-dimensional representation, often called the context vector($h_t$). The decoder generates the output sequence based on the encoded context vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d49aee",
   "metadata": {},
   "source": [
    "Let's look closer into the encoder and decoder boxes in the video below. Translation is a typical sequence-to-sequence task. The input is a sequence of words in the original language(\"I love to travel\"), while output is its translation in the destination language(\"J'adore voyager\"). As shown in the video, input is fed into the decoder part, one word after another. Each RNN cell receives a word($x_t$) and has an internal memory($h_t$). After processing the input and $h_t$, RNN cell passes an updated context vector($h_{t+1}$) to the next RNN cell. When the end of sentence is reached, the context vector is passed to the decoder part. Decoder cells are also RNN cells that receive context vector and generate the output word by word. Each RNN receives the generated word as well as the updated context vector from its previous cell and generates the next word($y_t$). This architecture allows for generating text without length restrictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32cdb30",
   "metadata": {},
   "source": [
    "### Encoder Implementation in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e2091c",
   "metadata": {},
   "source": [
    "To implement the encoder part using Pytorch, we will create the sub-class of the torch.nn.Module class and define the __init__() and __forward__() method.\n",
    "\n",
    "Let's first define the parameters that are used in __init__() function:\n",
    "- The `vocab_len` is nothing but the number of unique words present in the vocabulary. After pre-processing the data, we can count the number of unique words in our vocabulary and use that count here. This will be the dimension of the model input.\n",
    "- The embedding_dim is the output dimension of the embedding vector we need. A good practice is to use 256-512 for sample demo app like ywou are building here.\n",
    "- LSTM can indeed be stacked, allowing for multiple layers. In the initial implementation, we will use only one layer. However, to accommodate future flexibility, we will pass the parameter `n_layers` to specify the number of layers in the LSTM.\n",
    "- `hid_dim` is the dimensionality of the hidden and cell states.\n",
    "- `dropout` is the amount of dropout to use. This is a regularization parameter to prevent overfitting.\n",
    "\n",
    "Now, let's look into the layers:\n",
    "- The Embedding layer takes the input data and outputs the embedding vector, hence the dimension of those needs to be defined as `vocab_len` and `embedding_dim`.\n",
    "- The LSTM Layer takes the `embedding_dim` as the input data and creates total 3 outputs: `hidden`, `cell` and `output`. Here we need to define the number of neurons we need in LSTM, which is defined using the `hid_dim`.\n",
    "\n",
    "\n",
    "In the __forward__() function, the Embedding layer is defined that utilizes the `vocab_len` to internally convert the input_batch into a one-hot representation. Next, the LSTM layer receives the embedded input and outputs three vectors: Output, Hidden and cell. As for the encoder, we don't require the output vector from the LSTM as we only pass the context vector(`hidden`+`cell`) to the decoder block. Therefore, forward() only returns hidden and cell.\n",
    "\n",
    "Note: When using an LSTM, we have an additional cell state. However, if we were using a GRU, we would only have the hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96d1ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_len, emb_dim, hid_dim, n_layers, dropout_prob):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim \n",
    "        self.n_layers = n_layers \n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_len, emb_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout_prob)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        # input_batch = [src len, batch size]\n",
    "        embed = self.dropout(self.embedding(input_batch))\n",
    "        embed = embed.to(device)\n",
    "        # outputs = [src len, batch size, hid dim * n directions]\n",
    "        # hidden = [n_layers * n directions, batch size, hid dim]\n",
    "        # cell = [n layers * n directions, batch size, hid dim]\n",
    "        outputs, (hidden, cell) = self.lstm(embed)\n",
    "        return hidden, cell "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1ebcae",
   "metadata": {},
   "source": [
    "Now we are ready to create an encoder instance to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8efc6e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = 8 \n",
    "emb_dim = 10 \n",
    "hid_dim = 8 \n",
    "n_layers = 1 \n",
    "dropout_prob = 0.5 \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder_t = Encoder(vocab_len, emb_dim, hid_dim, n_layers, dropout_prob).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e56662",
   "metadata": {},
   "source": [
    "Let us see a simple example where encoder forward method transforms the `src` sentence into a `hidden` and `cell` states. tensor([[0],[3],[4],[2],[1]]) is equal to `src` = 0,3,4,2,1 in which each number represents a token in the `src` vocabulary. For instance, 0:`<bos>`,3:\"Das\", 4:\"ist\",2:\"sch√∂n\", 1:`<eos>`. Note that here we have batch size of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38ab6cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input(src) tensor: torch.Size([5, 1])\n",
      "Hidden tensor form encoder:  tensor([[[-0.2812, -0.0671, -0.1898,  0.4412,  0.0385,  0.4039, -0.1979,\n",
      "           0.3826]]], grad_fn=<StackBackward0>) \n",
      "Cel tensor from encoder: tensor([[[-0.4072, -0.1199, -0.6926,  1.2488,  0.0708,  0.5205, -0.3195,\n",
      "           0.7960]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "src_batch = torch.tensor([[0, 3, 4, 2, 1]])\n",
    "# We need to transpose the input tensor as the the encoder LSTM is in Sequence_first mode by default\n",
    "src_batch = src_batch.t().to(device)\n",
    "print(\"Shape of input(src) tensor:\", src_batch.shape)\n",
    "hidden_t, cell_t = encoder_t(src_batch)\n",
    "print(\"Hidden tensor form encoder: \", hidden_t, \"\\nCel tensor from encoder:\", cell_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50ed752",
   "metadata": {},
   "source": [
    "The encoder takes the entire source sequence as input, which consists of a sequence of words or tokens. The encoder LSTM processes the entire input sequence and updates its hidden states at each time step. The hidden states of the LSTM network act as a form of memory and capture the contextual information of the input sequence. After processing the entire input sequence, the final hidden state of the encoder LSTM captures the summarized representation of the input sequence's context. This final hidden state is sometimes referred to as the \"context vector\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711428a3",
   "metadata": {},
   "source": [
    "### Decoder implementation in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07679847",
   "metadata": {},
   "source": [
    "The decoder class inherits from nn.Module, which is a base class for all neural network modules in PyTorch.\n",
    "The constructor (__init__ method) initializes the parameters and layers of the decoder.\n",
    "- `output_dim` is the number of possible output values(target vocab length).\n",
    "- `emb_dim` is the dimensionality of the embedding layer.\n",
    "- `hid_dim` is the dimensionality of the hidden state in the LSTM.\n",
    "- `n_layers` is the number of layers in the LSTM.\n",
    "- `dropout` is the dropout probability.\n",
    "\n",
    "The decoder contains the following layers:\n",
    "- `embedding`: An embedding layer that maps the output values to dense vectors of size emb_dim.\n",
    "- `lstm`: An LSTM layer that takes the embedded input and produces hidden states of size hid_dim.\n",
    "-  `fc_out`: A linear layer that maps the LSTM output to the output dimension output_dim.\n",
    "- `softmax`: A log-softmax activation function applied to the output to obtain a probability distribution over the output values.\n",
    "- `dropout`: A dropout layer that applies dropout to the embedded input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa1a2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim \n",
    "        self.hid_dim = hid_dim \n",
    "        self.n_layers = n_layers \n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        #input = [batch size]\n",
    "\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "\n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch size]\n",
    "\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1, batch size, emb dim]\n",
    "\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        # output = [seq len, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        # cell = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "\n",
    "        prediction_logit = self.fc_out(output.squeeze(0))\n",
    "        prediction = self.softmax(prediction_logit)\n",
    "        # prediction = [batch size, output dim]\n",
    "\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d21c7d7",
   "metadata": {},
   "source": [
    "We can create a decoder instance. The output dimension is set as the target vocab length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d95e655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 6\n",
    "emb_dim=10\n",
    "hid_dim = 8\n",
    "n_layers=1\n",
    "dropout=0.5\n",
    "decoder_t = Decoder(output_dim, emb_dim, hid_dim, n_layers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eef0537",
   "metadata": {},
   "source": [
    "Now that we have instances of both encoder and decoder, we are ready to connect them (the red box in the diagram below). First, let's see how yowe can pass the Hidden and Cell (the pink cell within the red box) from encoder (the green boxes container) to decoder (the orange boxes container). Looking at the diagram, we can see that the decoder also receives an input which is the previous word that it has predicted. For the first decoder cell, this input is `<bos>` token. Each decoder cell outputs a prediction and updates the cell and state to pass to the next decoder cell. prediction is a probability distribution over possible target tokens (length of target vocab).\n",
    "\n",
    "![connection](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/ED_connection.JPG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "749d2bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[-2.1499, -1.8362, -1.5055, -2.0642, -1.7317, -1.6181]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) \n",
      "Hidden: tensor([[[ 0.0489, -0.1950, -0.7058, -0.2469,  0.0457,  0.3737, -0.0539,\n",
      "           0.0775]]], grad_fn=<StackBackward0>) \n",
      "Cell: tensor([[[ 0.0812, -0.3178, -1.2256, -0.3374,  0.1167,  0.4971, -0.1900,\n",
      "           0.2833]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_t = torch.tensor([0]).to(device) #<bos>\n",
    "input_t.shape\n",
    "prediction, hidden, cell = decoder_t(input_t, hidden_t , cell_t)\n",
    "print(\"Prediction:\", prediction, '\\nHidden:',hidden,'\\nCell:', cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582d941",
   "metadata": {},
   "source": [
    "### Encoder-Decoder Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc3812f",
   "metadata": {},
   "source": [
    "We created encoder and decoder modules. Now we need to create the connection so that the model can process (`src`,`trg`) pairs and generate the translation. suppose that `trg` is tensor ([[0],[2],[3],[5],[1]]) which is equal to sequence 0,2,3,5,1 in which each number represents a token in the target vocabulary. For instance, 0:`<bos>`,2:\"this\", 3:\"is\",5:\"beautiful\", 1:`<eos>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44343825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-1.9957, -1.7679, -1.7554, -2.0933, -1.6236, -1.6090]],\n",
      "\n",
      "        [[-1.9399, -1.9500, -1.7452, -2.0080, -1.4615, -1.7530]],\n",
      "\n",
      "        [[-1.9992, -1.8682, -1.7348, -1.9827, -1.5080, -1.7450]],\n",
      "\n",
      "        [[-1.9710, -2.0390, -1.6403, -1.9306, -1.4265, -1.8878]]],\n",
      "       grad_fn=<CopySlices>) torch.Size([5, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#trg = [trg len, batch size]\n",
    "#teacher_forcing_ratio is probability to use teacher forcing\n",
    "#e.g. if teacher_forcing_ratio is 0.75 you use ground-truth inputs 75% of the time\n",
    "teacher_forcing_ratio = 0.5\n",
    "trg = torch.tensor([[0],[2],[3],[5],[1]]).to(device)\n",
    "\n",
    "\n",
    "batch_size = trg.shape[1]\n",
    "trg_len = trg.shape[0]\n",
    "trg_vocab_size = decoder_t.output_dim\n",
    "\n",
    "#tensor to store decoder outputs\n",
    "outputs_t = torch.zeros(trg_len, batch_size, trg_vocab_size).to(device)\n",
    "\n",
    "#send to device\n",
    "\n",
    "hidden_t = hidden_t.to(device)\n",
    "cell_t = cell_t.to(device)\n",
    "\n",
    "\n",
    "#first input to the decoder is the <bos> tokens\n",
    "input = trg[0,:]\n",
    "\n",
    "\n",
    "for t in range(1, trg_len):\n",
    "\n",
    "    #you loop through the trg len and generate tokens\n",
    "    #decoder receives previous generated token, cell and hidden\n",
    "    # decoder outputs it prediction(probablity distribution for the next token) and updates hidden and cell\n",
    "    output_t, hidden_t, cell_t = decoder_t(input, hidden_t, cell_t)\n",
    "\n",
    "    #place predictions in a tensor holding predictions for each token\n",
    "    outputs_t[t] = output_t\n",
    "\n",
    "    #decide if you are going to use teacher forcing or not\n",
    "    teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "    #get the highest predicted token from your predictions\n",
    "    top1 = output_t.argmax(1)\n",
    "\n",
    "\n",
    "    #if teacher forcing, use actual next token as next input\n",
    "    #if not, use predicted token\n",
    "    #input = trg[t] if teacher_force else top1\n",
    "    input = trg[t] if teacher_force else top1\n",
    "\n",
    "print(outputs_t,outputs_t.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbdbb0a",
   "metadata": {},
   "source": [
    "The size of output tensor is (trg_len, batch_size, trg_vocab_size). This is because for each `trg` token (length of `trg`) the model outputs a probability distribution over all possible tokens(trg vocab length). Therefore, to generate the predicted tokens or translation of the `src` sentence, we need to get the maximum probability for each token:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d00a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [5],\n",
      "        [4],\n",
      "        [4],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "# Note that we need to get the argmax from the second dimension as **outputs** is an array of **output** tensors\n",
    "pred_tokens = outputs_t.argmax(2)\n",
    "print(pred_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6947c714",
   "metadata": {},
   "source": [
    "It is no surprise that the translation is not correct (trg = tensor([[0],[2],[3],[5],[1]]) as the model has not yet gone through any training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024770a",
   "metadata": {},
   "source": [
    "### Sequence-to-Sequence Model Implementation in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf91dac3",
   "metadata": {},
   "source": [
    "Let's connect encoder and decoder components to create the seq2seq model.\n",
    "\n",
    "We define the seq2seq class that inherits from nn.Module, which is the base class for all neural network modules in PyTorch.\n",
    "Inputs are:\n",
    "- `encoder` and `decoder` are instances of the encoder and decoder networks that we have already defined.\n",
    "- `device` specifies the device (e.g., CPU or GPU) on which the computations will be performed.\n",
    "- `trg_vocab` represents the vocabulary of the target language. It is used to determine the size of the output vocabulary.\n",
    "\n",
    "**forward** method defines the forward pass of the seq2seq model. It takes three arguments: `src`, `trg`, and `teacher_forcing_ratio`.:\n",
    "\n",
    "- `src` represents the source sequences, and `trg` represents the target sequences.\n",
    "- `teacher_forcing_ratio` is a probability that determines whether teacher forcing will be used during training only. Teacher forcing is a technique where the true target sequence is fed as input to the decoder at each time step, instead of using the predicted output from the previous time step.\n",
    "\n",
    "The **forward** method initializes some variables needed for the forward pass, such as `batch_size`, `trg_len`, and `trg_vocab_size`. It also creates an empty tensor called `outputs` to store the decoder outputs for each time step.\n",
    "\n",
    "The `hidden` and `cell` states of the encoder are obtained by calling the encoder (src) method. These states are then used as the initial states for the decoder.\n",
    "\n",
    "The input to the decoder at the first time step is the <bos> token of the target sequences.\n",
    "\n",
    "The decoder is iterated over for each time step in the target sequences (`for t in range(1, trg_len)`). The input, along with the previous hidden and cell states, is passed to the decoder, and it produces an output tensor. The `output` tensor is stored in the `outputs` tensor.\n",
    "\n",
    "At each time step, there is a decision made whether to use teacher forcing or not based on the teacher_forcing_ratio probability. If teacher forcing is used, the true next token from the target sequences (`trg[t]`) is used as the input for the next time step. Otherwise, the predicted token from the previous time step (`top1 = output.argmax(1)`) is used.\n",
    "\n",
    "Finally, the `outputs` tensor containing the predicted outputs for each time step is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b28cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device,trg_vocab):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.trg_vocab = trg_vocab\n",
    "\n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 you use ground-truth inputs 75% of the time\n",
    "\n",
    "\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        hidden = hidden.to(device)\n",
    "        cell = cell.to(device)\n",
    "\n",
    "\n",
    "        #first input to the decoder is the <bos> tokens\n",
    "        input = trg[0,:]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "\n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "\n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "\n",
    "            #decide if you are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            #get the highest predicted token from your predictions\n",
    "            top1 = output.argmax(1)\n",
    "\n",
    "\n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            #input = trg[t] if teacher_force else top1\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50583fd0",
   "metadata": {},
   "source": [
    "### Training Model in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd0b8d1",
   "metadata": {},
   "source": [
    "Now that the model is defined, we define a train function the seq2seq model. Let's go through the code and understand its components:\n",
    "\n",
    "1. `train(model, iterator, optimizer, criterion, clip)` takes five arguments:\n",
    "\n",
    "   - `model` is the model that will be trained.\n",
    "   - `iterator` is an iterable object that provides the training data in batches.\n",
    "   - `optimizer` is the optimization algorithm used to update the model's parameters.\n",
    "   - `criterion` is the loss function that measures the model's performance.\n",
    "   - `clip` is a value used to clip the gradients to prevent them from becoming too large during backpropagation.\n",
    "\n",
    "2. The function starts by setting the model to training mode with `model.train()`. This is necessary to enable certain layers (e.g., dropout) that behave differently during training and evaluation.\n",
    "\n",
    "3. It initializes a variable `epoch_loss` to keep track of the accumulated loss during the epoch.\n",
    "\n",
    "4. The function iterates over the training data provided by the `iterator`. Each iteration retrieves a batch of input sequences (`src`) and target sequences (`trg`).\n",
    "\n",
    "5. The input sequences (`src`) and target sequences (`trg`) are moved to the appropriate device (e.g., GPU) using `src = src.to(device)` and `trg = trg.to(device)`.\n",
    "\n",
    "6. The gradients of the model's parameters are cleared using `optimizer.zero_grad()` to prepare for the new batch.\n",
    "\n",
    "7. The model is then called with `output = model(src, trg)` to obtain the model's predictions for the target sequences.\n",
    "\n",
    "8. The `output` tensor has dimensions `[trg len, batch size, output dim]`. To calculate the loss, the tensor is reshaped to `[trg len - 1, batch size, output dim]` to remove the initial `<bos>` token, which is not used for calculating the loss.\n",
    "\n",
    "9. The target sequences (`trg`) are also reshaped to `[trg len - 1]` by removing the initial `<bos>` token and making it a contiguous tensor. This matches the shape of the reshaped `output` tensor.\n",
    "\n",
    "10. The loss between the reshaped `output` and `trg` tensors is calculated using the specified `criterion`.\n",
    "\n",
    "11. The gradients of the loss with respect to the model's parameters are computed using `loss.backward()`.\n",
    "\n",
    "12. The gradients are then clipped to a maximum value specified by `clip` using `torch.nn.utils.clip_grad_norm_(model.parameters(), clip)`. This prevents the gradients from becoming too large, which can cause issues during optimization.\n",
    "\n",
    "13. The optimizer's `step()` method is called to update the model's parameters using the computed gradients.\n",
    "\n",
    "14. The current batch loss (`loss.item()`) is added to the `epoch_loss` variable.\n",
    "\n",
    "15. After all the batches have been processed, the function returns the average loss per batch for the entire epoch, calculated as `epoch_loss / len(list(iterator))`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38a8157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    # Wrap iterator with tqdm for progress logging\n",
    "    train_iterator = tqdm(iterator, desc=\"Training\", leave=False)\n",
    "\n",
    "    for i, (src,trg) in enumerate(iterator):\n",
    "\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)\n",
    "\n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "\n",
    "        trg = trg[1:].contiguous().view(-1)\n",
    "\n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update tqdm progress bar with the current loss\n",
    "        train_iterator.set_postfix(loss=loss.item())\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "\n",
    "    return epoch_loss / len(list(iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adef969",
   "metadata": {},
   "source": [
    "### Evaluatin Model in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399e0017",
   "metadata": {},
   "source": [
    "We also need to define a function to evaluate the model. Let's go through the code and understand its components:\n",
    "\n",
    "1. `evaluate(model, iterator, criterion)` takes three arguments:\n",
    "   - `model` is the neural network model that will be evaluated.\n",
    "   - `iterator` is an iterable object that provides the evaluation data in batches.\n",
    "   - `criterion` is the loss function that measures the model's performance.\n",
    "* Note that evaluate function do not perform any optimization on the model.\n",
    "\n",
    "2. The function starts by setting the model to evaluation mode with `model.eval()`.\n",
    "\n",
    "3. It initializes a variable `epoch_loss` to keep track of the accumulated loss during the evaluation.\n",
    "\n",
    "4. The function enters a `with torch.no_grad()` block, which ensures that no gradients are computed during the evaluation. This saves memory and speeds up the evaluation process since gradients are not needed for parameter updates.\n",
    "\n",
    "5. The function iterates over the evaluation data provided by the `iterator`. Each iteration retrieves a batch of input sequences (`src`) and target sequences (`trg`).\n",
    "\n",
    "6. The input sequences (`src`) and target sequences (`trg`) are moved to the appropriate device (e.g., GPU) using `src = src.to(device)` and `trg = trg.to(device)`.\n",
    "\n",
    "7. The model is then called with `output = model(src, trg, 0)` to obtain the model's predictions for the target sequences. The third argument `0` is passed to indicate that teacher forcing is turned off during evaluation.  During evaluation, teacher forcing is typically turned off to evaluate the model's ability to generate sequences based on its own predictions.\n",
    "\n",
    "8. The `output` tensor has dimensions `[trg len, batch size, output dim]`. To calculate the loss, the tensor is reshaped to `[trg len - 1, batch size, output dim]` to remove the initial `<bos>` (beginning of sequence) token, which is not used for calculating the loss.\n",
    "\n",
    "9. The target sequences (`trg`) are also reshaped to `[trg len - 1]` by removing the initial `<bos>` token and making it a contiguous tensor. This matches the shape of the reshaped `output` tensor.\n",
    "\n",
    "10. The loss between the reshaped `output` and `trg` tensors is calculated using the specified `criterion`.\n",
    "\n",
    "11. The current batch loss (`loss.item()`) is added to the `epoch_loss` variable.\n",
    "\n",
    "12. After all the batches have been processed, the function returns the average loss per batch for the entire evaluation, calculated as `epoch_loss / len(list(iterator))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ea6bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    # Wrap iterator with tqdm for progress logging\n",
    "    valid_iterator = tqdm(iterator, desc=\"Training\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (src,trg) in enumerate(iterator):\n",
    "\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "\n",
    "            trg = trg[1:].contiguous().view(-1)\n",
    "\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            # Update tqdm progress bar with the current loss\n",
    "            valid_iterator.set_postfix(loss=loss.item())\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(list(iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e06748d",
   "metadata": {},
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b332611",
   "metadata": {},
   "source": [
    "In this section, we will fetch a language translation dataset called Multi30k, collate it (tokenization, numericalization, and adding BOS/EOS and padding) and create iterable batches of src and trg tensors.\n",
    "\n",
    "This leverages the predefined collate_fn to efficiently curate and ready batches for training the transformer model. The primary aim is to delve deeper into the intricacies of the RNN encoder and decoder components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "809a3740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Multi30K_de_en_dataloader.py', <http.client.HTTPMessage at 0x255c632fb50>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/Multi30K_de_en_dataloader.py\"\n",
    "urllib.request.urlretrieve(url, \"Multi30K_de_en_dataloader.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0df975d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic<2\n",
      "  Downloading pydantic-1.10.24-cp39-cp39-win_amd64.whl.metadata (156 kB)\n",
      "Collecting spacy==3.7.4\n",
      "  Using cached spacy-3.7.4-cp39-cp39-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy==3.7.4)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy==3.7.4)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy==3.7.4)\n",
      "  Using cached murmurhash-1.0.15-cp39-cp39-win_amd64.whl.metadata (2.3 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy==3.7.4)\n",
      "  Using cached cymem-2.0.13-cp39-cp39-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy==3.7.4)\n",
      "  Using cached preshed-3.0.12-cp39-cp39-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy==3.7.4)\n",
      "  Using cached thinc-8.2.5-cp39-cp39-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy==3.7.4)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy==3.7.4)\n",
      "  Using cached srsly-2.5.2-cp39-cp39-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy==3.7.4)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy==3.7.4)\n",
      "  Using cached weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy==3.7.4)\n",
      "  Using cached typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy==3.7.4)\n",
      "  Using cached smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0 (from spacy==3.7.4)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting requests<3.0.0,>=2.13.0 (from spacy==3.7.4)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting jinja2 (from spacy==3.7.4)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting setuptools (from spacy==3.7.4)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting packaging>=20.0 (from spacy==3.7.4)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy==3.7.4)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting numpy>=1.19.0 (from spacy==3.7.4)\n",
      "  Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl.metadata (59 kB)\n",
      "Collecting typing-extensions>=4.2.0 (from pydantic<2)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy==3.7.4)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.13.0->spacy==3.7.4)\n",
      "  Downloading charset_normalizer-3.4.4-cp39-cp39-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.13.0->spacy==3.7.4)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.13.0->spacy==3.7.4)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.13.0->spacy==3.7.4)\n",
      "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy==3.7.4)\n",
      "  Using cached blis-0.7.11-cp39-cp39-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy==3.7.4)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.19.0 (from spacy==3.7.4)\n",
      "  Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "Collecting colorama (from tqdm<5.0.0,>=4.38.0->spacy==3.7.4)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting click<9.0.0,>=7.1.1 (from typer<0.10.0,>=0.3.0->spacy==3.7.4)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy==3.7.4)\n",
      "  Using cached cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.7.4)\n",
      "  Using cached marisa_trie-1.3.1-cp39-cp39-win_amd64.whl.metadata (10 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->spacy==3.7.4)\n",
      "  Using cached markupsafe-3.0.3-cp39-cp39-win_amd64.whl.metadata (2.8 kB)\n",
      "Using cached spacy-3.7.4-cp39-cp39-win_amd64.whl (12.2 MB)\n",
      "Downloading pydantic-1.10.24-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.8/2.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 4.0 MB/s  0:00:00\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.13-cp39-cp39-win_amd64.whl (40 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Using cached murmurhash-1.0.15-cp39-cp39-win_amd64.whl (25 kB)\n",
      "Using cached preshed-3.0.12-cp39-cp39-win_amd64.whl (118 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp39-cp39-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.2-cp39-cp39-win_amd64.whl (654 kB)\n",
      "Using cached thinc-8.2.5-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Using cached blis-0.7.11-cp39-cp39-win_amd64.whl (6.6 MB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "Using cached cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached marisa_trie-1.3.1-cp39-cp39-win_amd64.whl (143 kB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached markupsafe-3.0.3-cp39-cp39-win_amd64.whl (15 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: urllib3, typing-extensions, spacy-loggers, spacy-legacy, smart-open, setuptools, packaging, numpy, murmurhash, MarkupSafe, marisa-trie, idna, cymem, colorama, charset_normalizer, certifi, catalogue, wasabi, tqdm, srsly, requests, pydantic, preshed, language-data, jinja2, cloudpathlib, click, blis, typer, langcodes, confection, weasel, thinc, spacy\n",
      "\n",
      "  Attempting uninstall: urllib3\n",
      "\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "\n",
      "   ----------------------------------------  0/34 [urllib3]\n",
      "   ----------------------------------------  0/34 [urllib3]\n",
      "   ----------------------------------------  0/34 [urllib3]\n",
      "  Attempting uninstall: typing-extensions\n",
      "   ----------------------------------------  0/34 [urllib3]\n",
      "    Found existing installation: typing_extensions 4.15.0\n",
      "   ----------------------------------------  0/34 [urllib3]\n",
      "    Uninstalling typing_extensions-4.15.0:\n",
      "   ----------------------------------------  0/34 [urllib3]\n",
      "   - --------------------------------------  1/34 [typing-extensions]\n",
      "   - --------------------------------------  1/34 [typing-extensions]\n",
      "   - --------------------------------------  1/34 [typing-extensions]\n",
      "   - --------------------------------------  1/34 [typing-extensions]\n",
      "   - --------------------------------------  1/34 [typing-extensions]\n",
      "   - --------------------------------------  1/34 [typing-extensions]\n",
      "      Successfully uninstalled typing_extensions-4.15.0\n",
      "   - --------------------------------------  1/34 [typing-extensions]\n",
      "  Attempting uninstall: spacy-loggers\n",
      "   - --------------------------------------  1/34 [typing-extensions]\n",
      "    Found existing installation: spacy-loggers 1.0.5\n",
      "   - --------------------------------------  1/34 [typing-extensions]\n",
      "   -- -------------------------------------  2/34 [spacy-loggers]\n",
      "    Uninstalling spacy-loggers-1.0.5:\n",
      "   -- -------------------------------------  2/34 [spacy-loggers]\n",
      "      Successfully uninstalled spacy-loggers-1.0.5\n",
      "   -- -------------------------------------  2/34 [spacy-loggers]\n",
      "   -- -------------------------------------  2/34 [spacy-loggers]\n",
      "  Attempting uninstall: spacy-legacy\n",
      "   -- -------------------------------------  2/34 [spacy-loggers]\n",
      "    Found existing installation: spacy-legacy 3.0.12\n",
      "   -- -------------------------------------  2/34 [spacy-loggers]\n",
      "    Uninstalling spacy-legacy-3.0.12:\n",
      "   -- -------------------------------------  2/34 [spacy-loggers]\n",
      "      Successfully uninstalled spacy-legacy-3.0.12\n",
      "   -- -------------------------------------  2/34 [spacy-loggers]\n",
      "   --- ------------------------------------  3/34 [spacy-legacy]\n",
      "  Attempting uninstall: smart-open\n",
      "   --- ------------------------------------  3/34 [spacy-legacy]\n",
      "    Found existing installation: smart-open 6.4.0\n",
      "   --- ------------------------------------  3/34 [spacy-legacy]\n",
      "    Uninstalling smart-open-6.4.0:\n",
      "   --- ------------------------------------  3/34 [spacy-legacy]\n",
      "      Successfully uninstalled smart-open-6.4.0\n",
      "   --- ------------------------------------  3/34 [spacy-legacy]\n",
      "   ---- -----------------------------------  4/34 [smart-open]\n",
      "  Attempting uninstall: setuptools\n",
      "   ---- -----------------------------------  4/34 [smart-open]\n",
      "    Found existing installation: setuptools 80.9.0\n",
      "   ---- -----------------------------------  4/34 [smart-open]\n",
      "    Uninstalling setuptools-80.9.0:\n",
      "   ---- -----------------------------------  4/34 [smart-open]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "      Successfully uninstalled setuptools-80.9.0\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "  Attempting uninstall: packaging\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "    Found existing installation: packaging 25.0\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "    Uninstalling packaging-25.0:\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "      Successfully uninstalled packaging-25.0\n",
      "   ----- ----------------------------------  5/34 [setuptools]\n",
      "   ------- --------------------------------  6/34 [packaging]\n",
      "  Attempting uninstall: numpy\n",
      "   ------- --------------------------------  6/34 [packaging]\n",
      "    Found existing installation: numpy 1.26.4\n",
      "   ------- --------------------------------  6/34 [packaging]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "    Uninstalling numpy-1.26.4:\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "  Attempting uninstall: murmurhash\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "    Found existing installation: murmurhash 1.0.15\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "    Uninstalling murmurhash-1.0.15:\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "      Successfully uninstalled murmurhash-1.0.15\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "  Attempting uninstall: MarkupSafe\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "    Found existing installation: MarkupSafe 3.0.3\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "    Uninstalling MarkupSafe-3.0.3:\n",
      "   -------- -------------------------------  7/34 [numpy]\n",
      "   ---------- -----------------------------  9/34 [MarkupSafe]\n",
      "      Successfully uninstalled MarkupSafe-3.0.3\n",
      "   ---------- -----------------------------  9/34 [MarkupSafe]\n",
      "  Attempting uninstall: marisa-trie\n",
      "   ---------- -----------------------------  9/34 [MarkupSafe]\n",
      "    Found existing installation: marisa-trie 1.3.1\n",
      "   ---------- -----------------------------  9/34 [MarkupSafe]\n",
      "    Uninstalling marisa-trie-1.3.1:\n",
      "   ---------- -----------------------------  9/34 [MarkupSafe]\n",
      "   ----------- ---------------------------- 10/34 [marisa-trie]\n",
      "   ----------- ---------------------------- 10/34 [marisa-trie]\n",
      "   ----------- ---------------------------- 10/34 [marisa-trie]\n",
      "   ----------- ---------------------------- 10/34 [marisa-trie]\n",
      "   ----------- ---------------------------- 10/34 [marisa-trie]\n",
      "      Successfully uninstalled marisa-trie-1.3.1\n",
      "   ----------- ---------------------------- 10/34 [marisa-trie]\n",
      "   ----------- ---------------------------- 10/34 [marisa-trie]\n",
      "  Attempting uninstall: idna\n",
      "   ----------- ---------------------------- 10/34 [marisa-trie]\n",
      "    Found existing installation: idna 3.11\n",
      "   ----------- ---------------------------- 10/34 [marisa-trie]\n",
      "    Uninstalling idna-3.11:\n",
      "   ----------- ---------------------------- 10/34 [marisa-trie]\n",
      "      Successfully uninstalled idna-3.11\n",
      "   ----------- ---------------------------- 10/34 [marisa-trie]\n",
      "   ------------ --------------------------- 11/34 [idna]\n",
      "  Attempting uninstall: cymem\n",
      "   ------------ --------------------------- 11/34 [idna]\n",
      "    Found existing installation: cymem 2.0.13\n",
      "   ------------ --------------------------- 11/34 [idna]\n",
      "    Uninstalling cymem-2.0.13:\n",
      "   ------------ --------------------------- 11/34 [idna]\n",
      "      Successfully uninstalled cymem-2.0.13\n",
      "   ------------ --------------------------- 11/34 [idna]\n",
      "  Attempting uninstall: colorama\n",
      "   ------------ --------------------------- 11/34 [idna]\n",
      "    Found existing installation: colorama 0.4.6\n",
      "   ------------ --------------------------- 11/34 [idna]\n",
      "   --------------- ------------------------ 13/34 [colorama]\n",
      "    Uninstalling colorama-0.4.6:\n",
      "   --------------- ------------------------ 13/34 [colorama]\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "   --------------- ------------------------ 13/34 [colorama]\n",
      "   --------------- ------------------------ 13/34 [colorama]\n",
      "  Attempting uninstall: charset_normalizer\n",
      "   --------------- ------------------------ 13/34 [colorama]\n",
      "    Found existing installation: charset-normalizer 3.4.4\n",
      "   --------------- ------------------------ 13/34 [colorama]\n",
      "    Uninstalling charset-normalizer-3.4.4:\n",
      "   --------------- ------------------------ 13/34 [colorama]\n",
      "      Successfully uninstalled charset-normalizer-3.4.4\n",
      "   --------------- ------------------------ 13/34 [colorama]\n",
      "   ---------------- ----------------------- 14/34 [charset_normalizer]\n",
      "   ---------------- ----------------------- 14/34 [charset_normalizer]\n",
      "  Attempting uninstall: certifi\n",
      "   ---------------- ----------------------- 14/34 [charset_normalizer]\n",
      "    Found existing installation: certifi 2025.11.12\n",
      "   ---------------- ----------------------- 14/34 [charset_normalizer]\n",
      "    Uninstalling certifi-2025.11.12:\n",
      "   ---------------- ----------------------- 14/34 [charset_normalizer]\n",
      "      Successfully uninstalled certifi-2025.11.12\n",
      "   ---------------- ----------------------- 14/34 [charset_normalizer]\n",
      "  Attempting uninstall: catalogue\n",
      "   ---------------- ----------------------- 14/34 [charset_normalizer]\n",
      "    Found existing installation: catalogue 2.0.10\n",
      "   ---------------- ----------------------- 14/34 [charset_normalizer]\n",
      "    Uninstalling catalogue-2.0.10:\n",
      "   ---------------- ----------------------- 14/34 [charset_normalizer]\n",
      "      Successfully uninstalled catalogue-2.0.10\n",
      "   ---------------- ----------------------- 14/34 [charset_normalizer]\n",
      "  Attempting uninstall: wasabi\n",
      "   ---------------- ----------------------- 14/34 [charset_normalizer]\n",
      "    Found existing installation: wasabi 1.1.3\n",
      "   ---------------- ----------------------- 14/34 [charset_normalizer]\n",
      "   -------------------- ------------------- 17/34 [wasabi]\n",
      "    Uninstalling wasabi-1.1.3:\n",
      "   -------------------- ------------------- 17/34 [wasabi]\n",
      "      Successfully uninstalled wasabi-1.1.3\n",
      "   -------------------- ------------------- 17/34 [wasabi]\n",
      "   -------------------- ------------------- 17/34 [wasabi]\n",
      "  Attempting uninstall: tqdm\n",
      "   -------------------- ------------------- 17/34 [wasabi]\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "   -------------------- ------------------- 17/34 [wasabi]\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "   -------------------- ------------------- 17/34 [wasabi]\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "   -------------------- ------------------- 17/34 [wasabi]\n",
      "   --------------------- ------------------ 18/34 [tqdm]\n",
      "   --------------------- ------------------ 18/34 [tqdm]\n",
      "   --------------------- ------------------ 18/34 [tqdm]\n",
      "  Attempting uninstall: srsly\n",
      "   --------------------- ------------------ 18/34 [tqdm]\n",
      "    Found existing installation: srsly 2.5.2\n",
      "   --------------------- ------------------ 18/34 [tqdm]\n",
      "    Uninstalling srsly-2.5.2:\n",
      "   --------------------- ------------------ 18/34 [tqdm]\n",
      "      Successfully uninstalled srsly-2.5.2\n",
      "   --------------------- ------------------ 18/34 [tqdm]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "  Attempting uninstall: requests\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "    Found existing installation: requests 2.32.4\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "    Uninstalling requests-2.32.4:\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "      Successfully uninstalled requests-2.32.4\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ----------------------- ---------------- 20/34 [requests]\n",
      "   ----------------------- ---------------- 20/34 [requests]\n",
      "  Attempting uninstall: pydantic\n",
      "   ----------------------- ---------------- 20/34 [requests]\n",
      "    Found existing installation: pydantic 2.12.5\n",
      "   ----------------------- ---------------- 20/34 [requests]\n",
      "    Uninstalling pydantic-2.12.5:\n",
      "   ----------------------- ---------------- 20/34 [requests]\n",
      "      Successfully uninstalled pydantic-2.12.5\n",
      "   ----------------------- ---------------- 20/34 [requests]\n",
      "   ------------------------ --------------- 21/34 [pydantic]\n",
      "   ------------------------ --------------- 21/34 [pydantic]\n",
      "   ------------------------ --------------- 21/34 [pydantic]\n",
      "   ------------------------ --------------- 21/34 [pydantic]\n",
      "  Attempting uninstall: preshed\n",
      "   ------------------------ --------------- 21/34 [pydantic]\n",
      "    Found existing installation: preshed 3.0.12\n",
      "   ------------------------ --------------- 21/34 [pydantic]\n",
      "    Uninstalling preshed-3.0.12:\n",
      "   ------------------------ --------------- 21/34 [pydantic]\n",
      "      Successfully uninstalled preshed-3.0.12\n",
      "   ------------------------ --------------- 21/34 [pydantic]\n",
      "   ------------------------- -------------- 22/34 [preshed]\n",
      "  Attempting uninstall: language-data\n",
      "   ------------------------- -------------- 22/34 [preshed]\n",
      "    Found existing installation: language_data 1.3.0\n",
      "   ------------------------- -------------- 22/34 [preshed]\n",
      "    Uninstalling language_data-1.3.0:\n",
      "   ------------------------- -------------- 22/34 [preshed]\n",
      "   --------------------------- ------------ 23/34 [language-data]\n",
      "      Successfully uninstalled language_data-1.3.0\n",
      "   --------------------------- ------------ 23/34 [language-data]\n",
      "   --------------------------- ------------ 23/34 [language-data]\n",
      "   --------------------------- ------------ 23/34 [language-data]\n",
      "   --------------------------- ------------ 23/34 [language-data]\n",
      "   --------------------------- ------------ 23/34 [language-data]\n",
      "   --------------------------- ------------ 23/34 [language-data]\n",
      "   --------------------------- ------------ 23/34 [language-data]\n",
      "   --------------------------- ------------ 23/34 [language-data]\n",
      "  Attempting uninstall: jinja2\n",
      "   --------------------------- ------------ 23/34 [language-data]\n",
      "    Found existing installation: Jinja2 3.1.6\n",
      "   --------------------------- ------------ 23/34 [language-data]\n",
      "    Uninstalling Jinja2-3.1.6:\n",
      "   --------------------------- ------------ 23/34 [language-data]\n",
      "      Successfully uninstalled Jinja2-3.1.6\n",
      "   --------------------------- ------------ 23/34 [language-data]\n",
      "   ---------------------------- ----------- 24/34 [jinja2]\n",
      "   ---------------------------- ----------- 24/34 [jinja2]\n",
      "   ---------------------------- ----------- 24/34 [jinja2]\n",
      "  Attempting uninstall: cloudpathlib\n",
      "   ---------------------------- ----------- 24/34 [jinja2]\n",
      "    Found existing installation: cloudpathlib 0.16.0\n",
      "   ---------------------------- ----------- 24/34 [jinja2]\n",
      "    Uninstalling cloudpathlib-0.16.0:\n",
      "   ---------------------------- ----------- 24/34 [jinja2]\n",
      "      Successfully uninstalled cloudpathlib-0.16.0\n",
      "   ---------------------------- ----------- 24/34 [jinja2]\n",
      "   ----------------------------- ---------- 25/34 [cloudpathlib]\n",
      "  Attempting uninstall: click\n",
      "   ----------------------------- ---------- 25/34 [cloudpathlib]\n",
      "    Found existing installation: click 8.1.8\n",
      "   ----------------------------- ---------- 25/34 [cloudpathlib]\n",
      "    Uninstalling click-8.1.8:\n",
      "   ----------------------------- ---------- 25/34 [cloudpathlib]\n",
      "      Successfully uninstalled click-8.1.8\n",
      "   ----------------------------- ---------- 25/34 [cloudpathlib]\n",
      "   ------------------------------ --------- 26/34 [click]\n",
      "   ------------------------------ --------- 26/34 [click]\n",
      "  Attempting uninstall: blis\n",
      "   ------------------------------ --------- 26/34 [click]\n",
      "    Found existing installation: blis 0.7.11\n",
      "   ------------------------------ --------- 26/34 [click]\n",
      "    Uninstalling blis-0.7.11:\n",
      "   ------------------------------ --------- 26/34 [click]\n",
      "      Successfully uninstalled blis-0.7.11\n",
      "   ------------------------------ --------- 26/34 [click]\n",
      "   ------------------------------- -------- 27/34 [blis]\n",
      "  Attempting uninstall: typer\n",
      "   ------------------------------- -------- 27/34 [blis]\n",
      "    Found existing installation: typer 0.9.4\n",
      "   ------------------------------- -------- 27/34 [blis]\n",
      "    Uninstalling typer-0.9.4:\n",
      "   ------------------------------- -------- 27/34 [blis]\n",
      "      Successfully uninstalled typer-0.9.4\n",
      "   ------------------------------- -------- 27/34 [blis]\n",
      "   -------------------------------- ------- 28/34 [typer]\n",
      "  Attempting uninstall: langcodes\n",
      "   -------------------------------- ------- 28/34 [typer]\n",
      "    Found existing installation: langcodes 3.5.0\n",
      "   -------------------------------- ------- 28/34 [typer]\n",
      "    Uninstalling langcodes-3.5.0:\n",
      "   -------------------------------- ------- 28/34 [typer]\n",
      "      Successfully uninstalled langcodes-3.5.0\n",
      "   -------------------------------- ------- 28/34 [typer]\n",
      "   ---------------------------------- ----- 29/34 [langcodes]\n",
      "  Attempting uninstall: confection\n",
      "   ---------------------------------- ----- 29/34 [langcodes]\n",
      "    Found existing installation: confection 0.1.5\n",
      "   ---------------------------------- ----- 29/34 [langcodes]\n",
      "    Uninstalling confection-0.1.5:\n",
      "   ---------------------------------- ----- 29/34 [langcodes]\n",
      "      Successfully uninstalled confection-0.1.5\n",
      "   ---------------------------------- ----- 29/34 [langcodes]\n",
      "   ----------------------------------- ---- 30/34 [confection]\n",
      "  Attempting uninstall: weasel\n",
      "   ----------------------------------- ---- 30/34 [confection]\n",
      "    Found existing installation: weasel 0.3.4\n",
      "   ----------------------------------- ---- 30/34 [confection]\n",
      "    Uninstalling weasel-0.3.4:\n",
      "   ----------------------------------- ---- 30/34 [confection]\n",
      "      Successfully uninstalled weasel-0.3.4\n",
      "   ----------------------------------- ---- 30/34 [confection]\n",
      "   ------------------------------------ --- 31/34 [weasel]\n",
      "   ------------------------------------ --- 31/34 [weasel]\n",
      "  Attempting uninstall: thinc\n",
      "   ------------------------------------ --- 31/34 [weasel]\n",
      "    Found existing installation: thinc 8.2.5\n",
      "   ------------------------------------ --- 31/34 [weasel]\n",
      "   ------------------------------------- -- 32/34 [thinc]\n",
      "    Uninstalling thinc-8.2.5:\n",
      "   ------------------------------------- -- 32/34 [thinc]\n",
      "      Successfully uninstalled thinc-8.2.5\n",
      "   ------------------------------------- -- 32/34 [thinc]\n",
      "   ------------------------------------- -- 32/34 [thinc]\n",
      "   ------------------------------------- -- 32/34 [thinc]\n",
      "   ------------------------------------- -- 32/34 [thinc]\n",
      "   ------------------------------------- -- 32/34 [thinc]\n",
      "   ------------------------------------- -- 32/34 [thinc]\n",
      "   ------------------------------------- -- 32/34 [thinc]\n",
      "   ------------------------------------- -- 32/34 [thinc]\n",
      "   ------------------------------------- -- 32/34 [thinc]\n",
      "  Attempting uninstall: spacy\n",
      "   ------------------------------------- -- 32/34 [thinc]\n",
      "    Found existing installation: spacy 3.7.4\n",
      "   ------------------------------------- -- 32/34 [thinc]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "    Uninstalling spacy-3.7.4:\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "      Successfully uninstalled spacy-3.7.4\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   ---------------------------------------- 34/34 [spacy]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 blis-0.7.11 catalogue-2.0.10 certifi-2025.11.12 charset_normalizer-3.4.4 click-8.1.8 cloudpathlib-0.16.0 colorama-0.4.6 confection-0.1.5 cymem-2.0.13 idna-3.11 jinja2-3.1.6 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.3.1 murmurhash-1.0.15 numpy-1.26.4 packaging-25.0 preshed-3.0.12 pydantic-1.10.24 requests-2.32.5 setuptools-80.9.0 smart-open-6.4.0 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.2 thinc-8.2.5 tqdm-4.67.1 typer-0.9.4 typing-extensions-4.15.0 urllib3-2.5.0 wasabi-1.1.3 weasel-0.3.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\sekai\\.conda\\envs\\myenv\\Lib\\site-packages\\~~mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\sekai\\.conda\\envs\\myenv\\Lib\\site-packages\\~~mpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\sekai\\.conda\\envs\\myenv\\Lib\\site-packages\\~rsly'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install \"pydantic<2\" \"spacy==3.7.4\" --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b4f7ee48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
      "     ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.5/14.6 MB 3.4 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 1.0/14.6 MB 2.4 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.3/14.6 MB 2.3 MB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 1.8/14.6 MB 2.2 MB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 2.1/14.6 MB 2.2 MB/s eta 0:00:06\n",
      "     ------- -------------------------------- 2.9/14.6 MB 2.4 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.7/14.6 MB 2.6 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 4.5/14.6 MB 2.7 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 5.5/14.6 MB 2.9 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 6.3/14.6 MB 3.0 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 6.8/14.6 MB 3.1 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.9/14.6 MB 3.2 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 8.9/14.6 MB 3.3 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 9.4/14.6 MB 3.3 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 10.0/14.6 MB 3.3 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 10.2/14.6 MB 3.2 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 10.7/14.6 MB 3.1 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 11.5/14.6 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 12.6/14.6 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 13.4/14.6 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.4/14.6 MB 3.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 14.6/14.6 MB 3.3 MB/s  0:00:04\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from de-core-news-sm==3.7.0) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.10.24)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2025.11.12)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.8)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.3)\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.7.0\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.8 MB 4.2 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 4.0 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.4/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 3.1/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.2/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 5.0/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.0/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.8/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.7/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.2/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 3.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 3.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 3.1 MB/s  0:00:04\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.24)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.11.12)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sekai\\.conda\\envs\\myenv\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.3)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download de_core_news_sm\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9e4dfd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Multi30K_de_en_dataloader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee1e2c7",
   "metadata": {},
   "source": [
    "We only need to call the function `get_translation_dataloader(batch_size = N, flip = True)` with an arbitrary bacth size `N` and setting flip to True in order for the LSTM encoder to receive input sequences in reverse order. This can help the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d5a863a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, valid_dataloader = get_translation_dataloaders(batch_size = 4)#,flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a93561",
   "metadata": {},
   "source": [
    "We can check the `src` and `trg` tensors: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "240a91b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    2,     2,     2,     2],\n",
       "         [    3,  5510,  5510, 12642],\n",
       "         [    1,     3,     3,     8],\n",
       "         [    1,     1,     1,  1701],\n",
       "         [    1,     1,     1,     3]]),\n",
       " tensor([[   2,    2,    2,    2],\n",
       "         [   3, 6650,  216,    6],\n",
       "         [   1, 4623,  110, 3398],\n",
       "         [   1,  259, 3913,  202],\n",
       "         [   1,  172, 1650,  109],\n",
       "         [   1, 9953, 3823,   37],\n",
       "         [   1,  115,   71,    3],\n",
       "         [   1,  692, 2808,    1],\n",
       "         [   1, 3428, 2187,    1],\n",
       "         [   1,    5,    5,    1],\n",
       "         [   1,    3,    3,    1]]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src, trg = next(iter(train_dataloader))\n",
    "src,trg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacf028e",
   "metadata": {},
   "source": [
    "We can also get the english and german strings using `index_to_eng` and `index_to_german` functions provided in the .py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "99b70f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________\n",
      "german\n",
      "<bos> Personen mit schwarzen H√ºten in der Innenstadt . <eos>\n",
      "<bos> Eine Gruppe Menschen protestiert in einer Stadt . <eos>\n",
      "<bos> Eine Gruppe teilt ihre politischen Ansichten mit . <eos>\n",
      "<bos> Mehrere Personen sitzen an einem felsigen Strand . <eos>\n",
      "________________\n",
      "english\n",
      "<bos> People in black hats gathered together downtown . <eos> <pad> <pad> <pad>\n",
      "<bos> A group of people protesting in a city . <eos> <pad> <pad>\n",
      "<bos> A group is letting their political opinion be known . <eos> <pad>\n",
      "<bos> A group of people are sitting on a rocky beach . <eos>\n",
      "________________\n",
      "german\n",
      "<bos> Zwei sitzende Personen mit H√ºten und Sonnenbrillen . <eos>\n",
      "<bos> Ein kleiner Junge mit Hut beim Angeln . <eos>\n",
      "<bos> Diese zwei Frauen haben Spa√ü im Giorgio's . <eos>\n",
      "<bos> Zwei kleine Kinder schlafen auf dem Sofa . <eos>\n",
      "________________\n",
      "english\n",
      "<bos> Two people sitting in hats and shades . <eos> <pad> <pad> <pad>\n",
      "<bos> A young boy in a hat is fishing by himself . <eos>\n",
      "<bos> These two women is at Giorgio 's having fun . <eos> <pad>\n",
      "<bos> Two young children are asleep on a couch . <eos> <pad> <pad>\n",
      "________________\n",
      "german\n",
      "<bos> Zwei junge M√§dchen marschieren in einem Umzug . <eos>\n",
      "<bos> Eine Frau l√§uft vor einer gestreiften Wand . <eos>\n",
      "<bos> Ein Mann f√§hrt Jet-Ski auf dem Ozean . <eos>\n",
      "<bos> Die st√§dtischen Stra√üenbahnen an einem sonnigen Tag . <eos>\n",
      "________________\n",
      "english\n",
      "<bos> Two young girls walk in a parade . <eos> <pad> <pad> <pad> <pad>\n",
      "<bos> A woman is running in front of a striped wall . <eos> <pad>\n",
      "<bos> A man rides a jet ski across the ocean . <eos> <pad> <pad>\n",
      "<bos> The urban trolly 's of a city on a sunny day . <eos>\n"
     ]
    }
   ],
   "source": [
    "data_itr = iter(train_dataloader)\n",
    "# moving forward in the dataset to reach sequences of longer length for illustration purpose. (Remember the dataset is sorted on sequence len for optimal padding)\n",
    "for n in range(1000):\n",
    "    german, english= next(data_itr)\n",
    "\n",
    "for n in range(3):\n",
    "    german, english=next(data_itr)\n",
    "    german=german.T\n",
    "    english=english.T\n",
    "    print(\"________________\")\n",
    "    print(\"german\")\n",
    "    for g in german:\n",
    "        print(index_to_german(g))\n",
    "    print(\"________________\")\n",
    "    print(\"english\")\n",
    "    for e in english:\n",
    "        print(index_to_eng(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d10560",
   "metadata": {},
   "source": [
    "* Note: When working with PyTorch tensors that represent data, it's important to understand the conventions around representing sequences. In most cases, the rows (the first dimension) in a PyTorch tensor represent individual samples, while the columns (the second dimension) represent features or time steps in the case of sequences. When dealing with sequences in PyTorch, it's common to use functions like `pad_sequence` to ensure that all sequences have the same length. Surprisingly, the padding operation is applied along the second dimension (columns), even though sequences are typically represented in the first dimension (rows). This can be confusing at first due to the way batches of sequences are represented. In many sequence-related tasks in PyTorch, especially when working with recurrent models like RNNs, LSTMs, and GRUs, batches of sequences are usually represented with the shape [sequence_length, batch_size, feature_size], where `sequence_length` refers to the length of the longest sequence within the batch(here it is equevalent to `src_len` or `trg_len`). If we check the src tensor above, we can see that the first word of of all sentences are in the first line, the second word of all sentences are in the second line, etc. That is why the first dimension is the length of the sequence.\n",
    "\n",
    "    When we use `pad_sequence`, it adds padding to the sequences in a batch so that they all have the same length, matching the length of the longest sequence. Since sequences are represented in the first dimension, the padding is applied along that dimension. As a result, the output tensor from `pad_sequence` will have the format [sequence_length, batch_size]. (Check the output for `src` and `trg` from the above cell.) This convention is commonly used because models like LSTMs expect the data to be in this format. However, if we're accustomed to working with more traditional tabular data in PyTorch, it can initially cause confusion. It's important to be aware of this convention to avoid potential errors and understand how to properly prepare and format sequence data for our models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d35808",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b1cb4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa6fed5",
   "metadata": {},
   "source": [
    "Now, define an instance of the model:\n",
    "\n",
    "- `enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)`: This line creates an instance of the `Encoder` class, which represents the encoder component of the Seq2Seq model. The `Encoder` class takes the input dimension, embedding dimension, hidden dimension, number of layers, and dropout probability as arguments.\n",
    "\n",
    "- `dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)`: This line creates an instance of the `Decoder` class, which represents the decoder component of the Seq2Seq model. The `Decoder` class takes the output dimension, embedding dimension, hidden dimension, number of layers, and dropout probability as arguments.\n",
    "\n",
    "- `model = Seq2Seq(enc, dec, device,trg_vocab = vocab_transform['en']).to(device)`: This line creates an instance of the `Seq2Seq` class, which represents the entire Seq2Seq model. The `Seq2Seq` class takes the encoder, decoder, and device (e.g., CPU or GPU) as arguments. It combines the encoder and decoder to form the complete Seq2Seq architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b9ec49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(vocab_transform['de'])\n",
    "OUTPUT_DIM = len(vocab_transform['en'])\n",
    "ENC_EMB_DIM = 128 #256\n",
    "DEC_EMB_DIM = 128 #256\n",
    "HID_DIM = 256 #512\n",
    "N_LAYERS = 1 #2\n",
    "ENC_DROPOUT = 0.3 #0.5\n",
    "DEC_DROPOUT = 0.3 #0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device,trg_vocab = vocab_transform['en']).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a6acbb",
   "metadata": {},
   "source": [
    "`def init_weights(m)`defines a function named `init_weights` that takes a module `m` as input. The purpose of this function is to initialize the weights of the neural network module.\n",
    "\n",
    "The next line `for name, param in m.named_parameters():` starts a loop that iterates over the named parameters of the module `m`. Each parameter is accessed as `param` and its corresponding name is accessed as `name`.\n",
    "\n",
    "`nn.init.uniform_(param.data, -0.08, 0.08)`initializes the parameter's data with values drawn from a uniform distribution between `-0.08` and `0.08`. The `nn.init.uniform_` function is provided by the PyTorch library and is used to initialize the weights of neural network parameters.\n",
    "\n",
    "Finally, `model.apply(init_weights)` applies the `init_weights` function to the `model` instance. This ensures that the weights of all the parameters in the model are initialized using the specified uniform distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9efa58cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(19214, 128)\n",
       "    (lstm): LSTM(128, 256, dropout=0.3)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(10837, 128)\n",
       "    (lstm): LSTM(128, 256, dropout=0.3)\n",
       "    (fc_out): Linear(in_features=256, out_features=10837, bias=True)\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (trg_vocab): Vocab()\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32404482",
   "metadata": {},
   "source": [
    "This code defines a function `count_parameters` that counts the number of trainable parameters in a given model. It then prints the count of trainable parameters in a formatted string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0ea75cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 7,422,165 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c69c9f2",
   "metadata": {},
   "source": [
    "The following cell sets up the optimizer and loss function for training the model.\n",
    "\n",
    "1. `optimizer = optim.Adam(model.parameters())`: This line creates an instance of the Adam optimizer and passes the model's parameters (`model.parameters()`) as the parameters to be optimized. The Adam optimizer is a popular optimization algorithm commonly used for training deep neural networks. It adjusts the model's parameters based on the gradients computed during backpropagation to minimize the loss function.\n",
    "\n",
    "2. `PAD_IDX = vocab_transform['en'].get_stoi()['<pad>']`: This line retrieves the index of the `<pad>` token in the target vocabulary.\n",
    "\n",
    "3. `criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)`: This line creates an instance of the CrossEntropyLoss criterion. The CrossEntropyLoss is a commonly used loss function for multi-class classification tasks. In this case, it is used for training the model to predict the next word in the translated sequence. The `ignore_index` parameter is set to `PAD_IDX`, which indicates that the loss should be ignored for any predictions where the target is the padding token. This is useful to exclude padding tokens from contributing to the loss during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f7b25aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "PAD_IDX = vocab_transform['en'].get_stoi()['<pad>']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f88a93",
   "metadata": {},
   "source": [
    "The following helper function provides a convenient way to calculate the elapsed time in minutes and seconds given the start and end times. It will be used to measure the time taken for each epoch during training or any other time-related calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0d2abb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "07faf982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 22m 40s\n",
      "\tTrain Loss: 4.393 | Train PPL:  80.879\n",
      "\t Val. Loss: 5.350 |  Val. PPL: 210.509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 22m 35s\n",
      "\tTrain Loss: 3.656 | Train PPL:  38.717\n",
      "\t Val. Loss: 4.755 |  Val. PPL: 116.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 23m 3s\n",
      "\tTrain Loss: 3.266 | Train PPL:  26.198\n",
      "\t Val. Loss: 4.383 |  Val. PPL:  80.067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "N_EPOCHS = 3 #run the training for at least 5 epochs\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "best_train_loss = float('inf')\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "train_PPLs = []\n",
    "valid_PPLs = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "    train_ppl = math.exp(train_loss)\n",
    "    valid_loss = evaluate(model, valid_dataloader, criterion)\n",
    "    valid_ppl = math.exp(valid_loss)\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'RNN-TR-model.pt')\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_PPLs.append(train_ppl)\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_PPLs.append(valid_ppl)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {train_ppl:7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {valid_ppl:7.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe565b2c",
   "metadata": {},
   "source": [
    "Let us visualize the model train and validaion losses over the training epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b0328544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a list of epoch numbers\n",
    "epochs = [epoch+1 for epoch in range(N_EPOCHS)]\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plotting the training and validation loss\n",
    "ax1.plot(epochs, train_losses, label='Train Loss', color='blue')\n",
    "ax1.plot(epochs, valid_losses, label='Validation Loss', color='orange')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss/PPL')\n",
    "\n",
    "# Plotting the training and validation perplexity\n",
    "ax2.plot(epochs, train_PPLs, label='Train PPL', color='green')\n",
    "ax2.plot(epochs, valid_PPLs, label='Validation PPL', color='red')\n",
    "ax2.set_ylabel('Perplexity')\n",
    "\n",
    "# Adjust the y-axis scaling for PPL plot\n",
    "ax2.set_ylim(bottom=min(min(train_PPLs), min(valid_PPLs)) - 10, top=max(max(train_PPLs), max(valid_PPLs)) + 10)\n",
    "\n",
    "# Set the legend\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "lines = lines1 + lines2\n",
    "labels = labels1 + labels2\n",
    "ax1.legend(lines, labels, loc='upper right')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb2e48a",
   "metadata": {},
   "source": [
    "### Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09b0453",
   "metadata": {},
   "source": [
    "Next, create a generator function that generates translations for input source senteces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1cf7fc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_translation(model, src_sentence, src_vocab, trg_vocab, max_len=50):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        src_tensor = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1).to(device)\n",
    "\n",
    "        # Pass the source tensor through the encoder\n",
    "        hidden, cell = model.encoder(src_tensor)\n",
    "\n",
    "        # Create a tensor to store the generated translation\n",
    "        # get_stoi() maps tokens to indices\n",
    "        trg_indexes = [trg_vocab.get_stoi()['<bos>']]  # Start with <bos> token\n",
    "\n",
    "        # Convert the initial token to a PyTorch tensor\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(1)  # Add batch dimension\n",
    "\n",
    "        # Move the tensor to the same device as the model\n",
    "        trg_tensor = trg_tensor.to(model.device)\n",
    "\n",
    "\n",
    "        # Generate the translation\n",
    "        for _ in range(max_len):\n",
    "\n",
    "            # Pass the target tensor and the previous hidden and cell states through the decoder\n",
    "            output, hidden, cell = model.decoder(trg_tensor[-1], hidden, cell)\n",
    "\n",
    "            # Get the predicted next token\n",
    "            pred_token = output.argmax(1)[-1].item()\n",
    "\n",
    "            # Append the predicted token to the translation\n",
    "            trg_indexes.append(pred_token)\n",
    "\n",
    "\n",
    "            # If the predicted token is the <eos> token, stop generating\n",
    "            if pred_token == trg_vocab.get_stoi()['<eos>']:\n",
    "                break\n",
    "\n",
    "            # Convert the predicted token to a PyTorch tensor\n",
    "            trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(1)  # Add batch dimension\n",
    "\n",
    "            # Move the tensor to the same device as the model\n",
    "            trg_tensor = trg_tensor.to(model.device)\n",
    "\n",
    "        # Convert the generated tokens to text\n",
    "        # get_itos() maps indices to tokens\n",
    "        trg_tokens = [trg_vocab.get_itos()[i] for i in trg_indexes]\n",
    "\n",
    "        # Remove the <sos> and <eos> from the translation\n",
    "        if trg_tokens[0] == '<bos>':\n",
    "            trg_tokens = trg_tokens[1:]\n",
    "        if trg_tokens[-1] == '<eos>':\n",
    "            trg_tokens = trg_tokens[:-1]\n",
    "\n",
    "        # Return the translation list as a string\n",
    "\n",
    "        translation = \" \".join(trg_tokens)\n",
    "\n",
    "        return translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d5fcf7",
   "metadata": {},
   "source": [
    "Now, we can check the model's output for a sample sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e550feea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Asian man is on the street of a building .\n"
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('RNN-TR-model.pt'))\n",
    "\n",
    "# Actual translation: Asian man sweeping the walkway.\n",
    "src_sentence = 'Ein asiatischer Mann kehrt den Gehweg.'\n",
    "\n",
    "\n",
    "generated_translation = generate_translation(model, src_sentence=src_sentence, src_vocab=vocab_transform['de'], trg_vocab=vocab_transform['en'], max_len=12)\n",
    "#generated_translation = \" \".join(generated_translation_list).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
    "print(generated_translation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dd9661",
   "metadata": {},
   "source": [
    "### BLEU score metric for evaluation\n",
    "While peplexity serves as a general metric to evaluate the performance of language model in predicting the correct next token, BLEU score is helpful in evaluating the quality of the final generated translation.\n",
    "Validating the results using BLEU score is helpful when there is more than a single valid translation for a sentence as we can include many translation versions in the reference list and compare the generated translation with different versions of translations.\n",
    "\n",
    "The BLEU (Bilingual Evaluation Understudy) score is a metric commonly used to evaluate the quality of machine-generated translations by comparing them to one or more reference translations. It measures the similarity between the generated translation and the reference translations based on n-gram matching.\n",
    "\n",
    "The BLEU score is calculated using the following formulas:\n",
    "\n",
    "1. **Precision**:\n",
    "   - Precision measures the proportion of n-grams in the generated translation that appear in the reference translations.\n",
    "   - Precision is calculated for each n-gram order (1 to N) and then combined using a geometric mean.\n",
    "   - The precision for a particular n-gram order is calculated as:\n",
    "   \n",
    "   $$\\text{Precision}_n(t) = \\frac{\\text{CountClip}_n(t)}{\\text{Count}_n(t)}$$\n",
    "   \n",
    "   where:\n",
    "     - $\\text{CountClip}_n(t)$ is the count of n-grams in the generated translation that appear in any reference translation, clipped by the maximum count of that n-gram in any single reference translation.\n",
    "     - $\\text{Count}_n(t)$ is the count of n-grams in the generated translation.\n",
    "\n",
    "2. . **Brevity penalty**:\n",
    "   - The brevity penalty accounts for the fact that shorter translations tend to have higher precision scores.\n",
    "   - It encourages translations that are closer in length to the reference translations.\n",
    "   - The brevity penalty is calculated as:\n",
    "   \n",
    "  $$\\text{BP} = \\begin{cases} 1 & \\text{if } c > r \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ e^{(1 - \\frac{r}{c})} & \\text{if } c \\leq r \\end{cases}$$\n",
    "   \n",
    "   where:\n",
    "     - $c$ is the total length of the generated translation.\n",
    "     - $r$ is the total length of the reference translations.\n",
    "\n",
    "3. **BLEU score**:\n",
    "   - The BLEU score is the geometric mean of the precisions, weighted by the brevity penalty.\n",
    "   - It is calculated as:\n",
    "   \n",
    "   $$\\text{BLEU} = \\text{BP} \\cdot \\exp(\\sum_{n=1}^{N}w_n \\log(\\text{Precision}_n(t)))$$\n",
    "   \n",
    "   where:\n",
    "     - $N$ is the maximum n-gram order.\n",
    "     - $w_n$ is the weight assigned to the precision at n-gram order $n$, commonly set as $\\frac{1}{N}$ for equal weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "56f03fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu_score(generated_translation, reference_translations):\n",
    "    # Convert the generated translations and reference translations into the expected format for sentence_bleu\n",
    "    references = [reference.split() for reference in reference_translations]\n",
    "    hypothesis = generated_translation.split()\n",
    "\n",
    "    # Calculate the BLEU score\n",
    "    bleu_score = sentence_bleu(references, hypothesis)\n",
    "\n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a278578",
   "metadata": {},
   "source": [
    "Let us calculate the BLUE score for a sample sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e29f3d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.2596535889340338\n"
     ]
    }
   ],
   "source": [
    "reference_translations = [\n",
    "    \"Asian man sweeping the walkway .\",\n",
    "    \"An asian man sweeping the walkway .\",\n",
    "    \"An Asian man sweeps the sidewalk .\",\n",
    "    \"An Asian man is sweeping the sidewalk .\",\n",
    "    \"An asian man is sweeping the walkway .\",\n",
    "    \"Asian man sweeping the sidewalk .\"\n",
    "]\n",
    "\n",
    "bleu_score = calculate_bleu_score(generated_translation, reference_translations)\n",
    "print(\"BLEU Score:\", bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4746c66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original German text: Menschen gehen auf der Stra√üe\n",
      "Translated English text: People walking down a city street .\n"
     ]
    }
   ],
   "source": [
    "# Define the German text to be translated\n",
    "german_text = \"Menschen gehen auf der Stra√üe\"\n",
    "\n",
    "# The function should be defined to accept the text, the model, source and target vocabularies, and the device as parameters.\n",
    "english_translation = generate_translation(\n",
    "    model, \n",
    "    src_sentence=german_text, \n",
    "    src_vocab=vocab_transform['de'], \n",
    "    trg_vocab=vocab_transform['en'], \n",
    "    max_len=50\n",
    ")\n",
    "\n",
    "# Display the original and translated text\n",
    "print(f\"Original German text: {german_text}\")\n",
    "print(f\"Translated English text: {english_translation}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
