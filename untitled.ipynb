{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70198547",
   "metadata": {},
   "source": [
    "## Exploring Generative AI Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c224c76c",
   "metadata": {},
   "source": [
    "#### Building a simple chatbot with transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d161f",
   "metadata": {},
   "source": [
    "We will be utilizing the transformers library from Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69acfdbc",
   "metadata": {},
   "source": [
    "##### Step 1: Installing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2224d9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.2.1-cp313-cp313-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sekai\\.conda\\envs\\ai\\lib\\site-packages (from transformers) (3.19.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sekai\\.conda\\envs\\ai\\lib\\site-packages (from transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sekai\\.conda\\envs\\ai\\lib\\site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading pyyaml-6.0.3-cp313-cp313-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\sekai\\.conda\\envs\\ai\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sekai\\.conda\\envs\\ai\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sekai\\.conda\\envs\\ai\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sekai\\.conda\\envs\\ai\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sekai\\.conda\\envs\\ai\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sekai\\.conda\\envs\\ai\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sekai\\.conda\\envs\\ai\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sekai\\.conda\\envs\\ai\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sekai\\.conda\\envs\\ai\\lib\\site-packages (from requests->transformers) (2025.10.5)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.0 MB 4.0 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 4.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.4/12.0 MB 4.1 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 4.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.2/12.0 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.0/12.0 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.8/12.0 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.8/12.0 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.6/12.0 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.4/12.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.4/12.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.2/12.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 4.2 MB/s  0:00:02\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 4.3 MB/s  0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.4/2.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 4.1 MB/s  0:00:00\n",
      "Downloading sentencepiece-0.2.1-cp313-cp313-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 0.8/1.1 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 4.1 MB/s  0:00:00\n",
      "Downloading pyyaml-6.0.3-cp313-cp313-win_amd64.whl (154 kB)\n",
      "Downloading regex-2025.11.3-cp313-cp313-win_amd64.whl (277 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Installing collected packages: sentencepiece, safetensors, regex, pyyaml, huggingface-hub, tokenizers, transformers\n",
      "\n",
      "   ----- ---------------------------------- 1/7 [safetensors]\n",
      "   ----------- ---------------------------- 2/7 [regex]\n",
      "   ----------------- ---------------------- 3/7 [pyyaml]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------------- ----------- 5/7 [tokenizers]\n",
      "   ---------------------------- ----------- 5/7 [tokenizers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------------- 7/7 [transformers]\n",
      "\n",
      "Successfully installed huggingface-hub-0.36.0 pyyaml-6.0.3 regex-2025.11.3 safetensors-0.6.2 sentencepiece-0.2.1 tokenizers-0.22.1 transformers-4.57.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers sentencepiece "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61acf7dc",
   "metadata": {},
   "source": [
    "##### Step 2: Importing the required tools from the transformers library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4677c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"facebook/blenderbot-400M-distill\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f418a2",
   "metadata": {},
   "source": [
    "We initiated variables using two invaluable classes from the transformers library: \n",
    "- `model` is an instance of the class `AutoModelForSeq2SeqLM`. This class lets you interact with your chosen language model.\n",
    "- `tokenizer` is an instance of the class `AutoTokenizer`. This class streamlines our input and presents it to the language model in the most efficient manner. It achieves this by converting our text input into \"tokens\", which is the model's preferred way of interpreting text. We chose \"facebook/blenderbot-400M-distill\" for this example model because it is freely available under an open-source license and operated at a relatively brisk pace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b873af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! How are you doing today? I just got back from a walk with my dog.\n",
      "Chatbot: It's when you lose interest in something you are passionate about. It's hard to get over that.\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Define the chat function \n",
    "def chat_with_bot():\n",
    "    while True:\n",
    "        # Get user input\n",
    "        input_text = input(\"You: \")\n",
    "\n",
    "        # Exit conditions \n",
    "        if input_text.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break \n",
    "\n",
    "        # Tokenize input and generate response \n",
    "        inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "        outputs = model.generate(inputs, max_new_tokens=150)\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "        # Display bot's reponse\n",
    "        print(\"Chatbot:\", response)\n",
    "\n",
    "# Initiate chat\n",
    "chat_with_bot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f177fff9",
   "metadata": {},
   "source": [
    "Let us try another model and compare the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c64e92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sekai\\.conda\\envs\\AI\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sekai\\.cache\\huggingface\\hub\\models--google--flan-t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece \n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e76b38db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  aloha\n",
      "Chatbot:  focalloss is a feature of deep learning that is not easily accounted for in the real world.\n",
      "Chatbot: Adios Amigo\n"
     ]
    }
   ],
   "source": [
    "def chat_with_bot():\n",
    "    while True:\n",
    "        input_text = input(\"You: \")\n",
    "\n",
    "        if input_text.lower() in ['quit', 'exit', 'bye']:\n",
    "            print(\"Chatbot: Adios Amigo\")\n",
    "            break \n",
    "\n",
    "        inputs = tokenizer.encode(input_text, return_tensors = \"pt\")\n",
    "        outputs = model.generate(inputs, max_new_tokens = 150)\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "        print(\"Chatbot: \", response)\n",
    "\n",
    "chat_with_bot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
